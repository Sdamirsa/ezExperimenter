{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit Test\n",
    "\n",
    "**For each test, you should click on the test function, and on top of the python file, you should define paths and parameters for testing.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### firework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generation.test_generation import firework_async_generate_test\n",
    "import asyncio\n",
    "\n",
    "await firework_async_generate_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## handlers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### excel_json_handlers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from handlers.test_handlers import test_excel_json_handlers\n",
    "\n",
    "await test_excel_json_handlers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run_multiple_experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from handlers.test_handlers import test_run_multiple_experiments\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "await test_run_multiple_experiments()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run - E1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### firework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_configs = [\n",
    "    {\n",
    "        'experiment_name': 'Llama-3.3-70b', #游릭\n",
    "        'excel_path': r\"C:\\Users\\LEGION\\Documents\\GIT\\LLM_answer_GIBoard\\DO_NOT_PUBLISH\\ACG self asses - 202412\\New results\\E1_Bestprompt-2022_all_Final_E2_manualevaluatedcompleted_Final_E2_Final.xlsx\",\n",
    "        \n",
    "        # 'excel_path': r\"C:\\Users\\LEGION\\Documents\\GIT\\LLM_answer_GIBoard\\DO_NOT_PUBLISH\\ACG self asses - 202412\\New results\\E1_Bestprompt-2022_all_Final_E2_manualevaluatedcompleted_Final_E2_Final.xlsx\",\n",
    "        'prompt_column': 'TEXT4WEB',\n",
    "        'temperature': 1,\n",
    "        'model':  'accounts/fireworks/models/llama-v3p3-70b-instruct',\n",
    "        \n",
    "        'max_tokens': 1024,\n",
    "        'system_prompt': None,\n",
    "        'batch_size': 30,\n",
    "        # pydantic_model = ,\n",
    "        # \"model_kwargs\" = {},\n",
    "        # \"start_row\" = 0,\n",
    "        # \"end_row\"=None,\n",
    "        # image_column = ,\n",
    "    },\n",
    "    {\n",
    "        'experiment_name': 'Llama-3.2-1b', #游릭\n",
    "        'excel_path': r\"C:\\Users\\LEGION\\Documents\\GIT\\LLM_answer_GIBoard\\DO_NOT_PUBLISH\\ACG self asses - 202412\\New results\\E1_Bestprompt-2022_all_Final_E2_manualevaluatedcompleted_Final_E2_Final.xlsx\",\n",
    "        \n",
    "        # 'excel_path': r\"C:\\Users\\LEGION\\Documents\\GIT\\LLM_answer_GIBoard\\DO_NOT_PUBLISH\\ACG self asses - 202412\\New results\\E1_Bestprompt-2022_all_Final_E2_manualevaluatedcompleted_Final_E2_Final.xlsx\",\n",
    "        'prompt_column': 'TEXT4WEB',\n",
    "        'temperature': 0.6,\n",
    "        'model':  'accounts/fireworks/models/llama-v3p2-1b-instruct',\n",
    "        \n",
    "        'max_tokens': 1024,\n",
    "        'system_prompt': None,\n",
    "        'batch_size': 30,\n",
    "        # pydantic_model = ,\n",
    "        # \"model_kwargs\" = {},\n",
    "        # \"start_row\" = 0,\n",
    "        # \"end_row\"=None,\n",
    "        # image_column = ,\n",
    "    },\n",
    "    {\n",
    "        'experiment_name': 'Llama-3.2-3b', #游릭\n",
    "        'excel_path': r\"C:\\Users\\LEGION\\Documents\\GIT\\LLM_answer_GIBoard\\DO_NOT_PUBLISH\\ACG self asses - 202412\\New results\\E1_Bestprompt-2022_all_Final_E2_manualevaluatedcompleted_Final_E2_Final.xlsx\",\n",
    "        \n",
    "        # 'excel_path': r\"C:\\Users\\LEGION\\Documents\\GIT\\LLM_answer_GIBoard\\DO_NOT_PUBLISH\\ACG self asses - 202412\\New results\\E1_Bestprompt-2022_all_Final_E2_manualevaluatedcompleted_Final_E2_Final.xlsx\",\n",
    "        'prompt_column': 'TEXT4WEB',\n",
    "        'temperature': 0.6,\n",
    "        'model':  'accounts/fireworks/models/llama-v3p2-3b-instruct',\n",
    "        \n",
    "        'max_tokens': 1024,\n",
    "        'system_prompt': None,\n",
    "        'batch_size': 30,\n",
    "        # pydantic_model = ,\n",
    "        # \"model_kwargs\" = {},\n",
    "        # \"start_row\" = 0,\n",
    "        # \"end_row\"=None,\n",
    "        # image_column = ,\n",
    "    },\n",
    "    {\n",
    "        'experiment_name': 'Llama-3.2-11b', #游릭\n",
    "        'excel_path': r\"C:\\Users\\LEGION\\Documents\\GIT\\LLM_answer_GIBoard\\DO_NOT_PUBLISH\\ACG self asses - 202412\\New results\\E1_Bestprompt-2022_all_Final_E2_manualevaluatedcompleted_Final_E2_Final.xlsx\",\n",
    "        \n",
    "        # 'excel_path': r\"C:\\Users\\LEGION\\Documents\\GIT\\LLM_answer_GIBoard\\DO_NOT_PUBLISH\\ACG self asses - 202412\\New results\\E1_Bestprompt-2022_all_Final_E2_manualevaluatedcompleted_Final_E2_Final.xlsx\",\n",
    "        'prompt_column': 'TEXT4WEB',\n",
    "        'temperature': 0.6,\n",
    "        'model':  'accounts/fireworks/models/llama-v3p2-11b-vision-instruct',\n",
    "        \n",
    "        'max_tokens': 1024,\n",
    "        'system_prompt': None,\n",
    "        'batch_size': 30,\n",
    "        # pydantic_model = ,\n",
    "        # \"model_kwargs\" = {},\n",
    "        # \"start_row\" = 0,\n",
    "        # \"end_row\"=None,\n",
    "        # image_column = ,\n",
    "    },\n",
    "    \n",
    "    {\n",
    "        'experiment_name': 'Phi-3.5-4b', #游릭\n",
    "        'excel_path': r\"C:\\Users\\LEGION\\Documents\\GIT\\LLM_answer_GIBoard\\DO_NOT_PUBLISH\\ACG self asses - 202412\\New results\\E1_Bestprompt-2022_all_Final_E2_manualevaluatedcompleted_Final_E2_Final.xlsx\",\n",
    "        \n",
    "        # 'excel_path': r\"C:\\Users\\LEGION\\Documents\\GIT\\LLM_answer_GIBoard\\DO_NOT_PUBLISH\\ACG self asses - 202412\\New results\\E1_Bestprompt-2022_all_Final_E2_manualevaluatedcompleted_Final_E2_Final.xlsx\",\n",
    "        'prompt_column': 'TEXT4WEB',\n",
    "        'temperature': 0.6,\n",
    "        'model':  'accounts/fireworks/models/phi-3-vision-128k-instruct',\n",
    "        \n",
    "        'max_tokens': 1024,\n",
    "        'system_prompt': None,\n",
    "        'batch_size': 5,\n",
    "        # pydantic_model = ,\n",
    "        # \"model_kwargs\" = {},\n",
    "        # \"start_row\" = 0,\n",
    "        # \"end_row\"=None,\n",
    "        # image_column = ,\n",
    "    },     \n",
    "    \n",
    "    # {\n",
    "    #     'experiment_name': 'Qwen-2.5-7b', \n",
    "    #     'excel_path': r\"C:\\Users\\LEGION\\Documents\\GIT\\LLM_answer_GIBoard\\DO_NOT_PUBLISH\\ACG self asses - 202412\\New results\\E1_Bestprompt-2022_all_Final_E2_manualevaluatedcompleted_Final_E2_Final.xlsx\",\n",
    "        \n",
    "    #     # 'excel_path': r\"C:\\Users\\LEGION\\Documents\\GIT\\LLM_answer_GIBoard\\DO_NOT_PUBLISH\\ACG self asses - 202412\\New results\\E1_Bestprompt-2022_all_Final_E2_manualevaluatedcompleted_Final_E2_Final.xlsx\",\n",
    "    #     'prompt_column': 'TEXT4WEB',\n",
    "    #     'temperature': 0.6,\n",
    "    #     'model':  'accounts/fireworks/models/qwen2p5-7b-instruct',\n",
    "        \n",
    "    #     'max_tokens': 1024,\n",
    "    #     'system_prompt': None,\n",
    "    #     'batch_size': 5,\n",
    "    #     # pydantic_model = ,\n",
    "    #     # \"model_kwargs\" = {},\n",
    "    #     # \"start_row\" = 0,\n",
    "    #     # \"end_row\"=None,\n",
    "    #     # image_column = ,\n",
    "    # },    \n",
    "    # {\n",
    "    #     'experiment_name': 'Phi-3-3b', \n",
    "    #     'excel_path': r\"C:\\Users\\LEGION\\Documents\\GIT\\LLM_answer_GIBoard\\DO_NOT_PUBLISH\\ACG self asses - 202412\\New results\\E1_Bestprompt-2022_all_Final_E2_manualevaluatedcompleted_Final_E2_Final.xlsx\",\n",
    "        \n",
    "    #     # 'excel_path': r\"C:\\Users\\LEGION\\Documents\\GIT\\LLM_answer_GIBoard\\DO_NOT_PUBLISH\\ACG self asses - 202412\\New results\\E1_Bestprompt-2022_all_Final_E2_manualevaluatedcompleted_Final_E2_Final.xlsx\",\n",
    "    #     'prompt_column': 'TEXT4WEB',\n",
    "    #     'temperature': 0.6,\n",
    "    #     'model':  'accounts/fireworks/models/phi-3-mini-128k-instruct',\n",
    "        \n",
    "    #     'max_tokens': 1024,\n",
    "    #     'system_prompt': None,\n",
    "    #     'batch_size': 5,\n",
    "    #     # pydantic_model = ,\n",
    "    #     # \"model_kwargs\" = {},\n",
    "    #     # \"start_row\" = 0,\n",
    "    #     # \"end_row\"=None,\n",
    "    #     # image_column = ,\n",
    "    # },        \n",
    "\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nest_asyncio\n",
    "import asyncio\n",
    "from Clean.handlers.async_experiment_handler import run_multiple_experiments\n",
    "from generation.firework.async_generator import firework_async_generate\n",
    "\n",
    "\n",
    "base_output_folder = r\"C:\\Users\\LEGION\\Documents\\GIT\\LLM_answer_GIBoard\\DO_NOT_PUBLISH\\ACG self asses - 202412\\New results\"\n",
    "firework_base_url=\"https://api.fireworks.ai/inference/v1\"\n",
    "firework_api_key = os.getenv(\"FIREWORKS_API_KEY\")\n",
    "\n",
    "\n",
    "results = await run_multiple_experiments(\n",
    "    experiment_configs=experiment_configs,\n",
    "    base_output_folder=base_output_folder,\n",
    "    generator_function=firework_async_generate,\n",
    "    base_url=firework_base_url,\n",
    "    api_key=firework_api_key\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_configs = [  \n",
    "    {\n",
    "        'experiment_name': 'Qwen-2.5-3b-it', \n",
    "        'excel_path': r\"C:\\Users\\LEGION\\Documents\\GIT\\LLM_answer_GIBoard\\DO_NOT_PUBLISH\\ACG self asses - 202412\\New results\\E1_Bestprompt-2022_all_Final_E2_manualevaluatedcompleted_Final_E2_Final.xlsx\",\n",
    "        \n",
    "        # 'excel_path': r\"C:\\Users\\LEGION\\Documents\\GIT\\LLM_answer_GIBoard\\DO_NOT_PUBLISH\\ACG self asses - 202412\\New results\\E1_Bestprompt-2022_all_Final_E2_manualevaluatedcompleted_Final_E2_Final.xlsx\",\n",
    "        'prompt_column': 'TEXT4WEB',\n",
    "        'temperature': 0.6,\n",
    "        'model':  \"Qwen/Qwen2.5-3B-Instruct\",\n",
    "        \n",
    "        'max_tokens': 1024,\n",
    "        'system_prompt': None,\n",
    "        'batch_size': 1,\n",
    "        # pydantic_model = ,\n",
    "        # \"model_kwargs\" = {},\n",
    "        # \"start_row\" = 0,\n",
    "        # \"end_row\"=None,\n",
    "        # image_column = ,\n",
    "    },     \n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nest_asyncio\n",
    "import asyncio\n",
    "from Clean.handlers.async_experiment_handler import run_multiple_experiments\n",
    "from generation.firework.async_generator import firework_async_generate\n",
    "\n",
    "\n",
    "base_output_folder = r\"C:\\Users\\LEGION\\Documents\\GIT\\LLM_answer_GIBoard\\DO_NOT_PUBLISH\\ACG self asses - 202412\\New results\"\n",
    "hf_base_url=\"https://api-inference.huggingface.co/v1/\"\n",
    "hf_api_key = os.getenv(\"HF_API_KEY\")\n",
    "\n",
    "\n",
    "results = await run_multiple_experiments(\n",
    "    experiment_configs=experiment_configs,\n",
    "    base_output_folder=base_output_folder,\n",
    "    generator_function=firework_async_generate,\n",
    "    base_url=hf_base_url,\n",
    "    api_key=hf_api_key\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_configs = [  \n",
    "\n",
    "    {\n",
    "        'experiment_name': 'Qwen-2.5-3b', #游릭\n",
    "        'excel_path': r\"C:\\Users\\LEGION\\Documents\\GIT\\LLM_answer_GIBoard\\DO_NOT_PUBLISH\\ACG self asses - 202412\\New results\\E1_Bestprompt-2022_all_Final_E2_manualevaluatedcompleted_Final_E2_Final.xlsx\",\n",
    "        \n",
    "        # 'excel_path': r\"C:\\Users\\LEGION\\Documents\\GIT\\LLM_answer_GIBoard\\DO_NOT_PUBLISH\\ACG self asses - 202412\\New results\\E1_Bestprompt-2022_all_Final_E2_manualevaluatedcompleted_Final_E2_Final.xlsx\",\n",
    "        'prompt_column': 'TEXT4WEB',\n",
    "        'temperature': 0.6,\n",
    "        'model':  'qwen2.5:3b',\n",
    "        \n",
    "        'max_tokens': 1024,\n",
    "        'system_prompt': None, # \"You are a helpful assistant.\"\n",
    "        'batch_size': 1,\n",
    "        # pydantic_model = ,\n",
    "        # \"model_kwargs\" = {},\n",
    "        # \"start_row\" = 0,\n",
    "        # \"end_row\"=None,\n",
    "        # image_column = ,\n",
    "    },        \n",
    "\n",
    "\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nest_asyncio\n",
    "import asyncio\n",
    "from handlers.async_experiment_handler import run_multiple_experiments\n",
    "from generation.firework.async_generator import firework_async_generate\n",
    "\n",
    "\n",
    "base_output_folder = r\"C:\\Users\\LEGION\\Documents\\GIT\\LLM_answer_GIBoard\\DO_NOT_PUBLISH\\ACG self asses - 202412\\New results\"\n",
    "ollama_base_url='http://localhost:11434/v1/'\n",
    "ollama_api_key = \"ollama\"\n",
    "\n",
    "\n",
    "results = await run_multiple_experiments(\n",
    "    experiment_configs=experiment_configs,\n",
    "    base_output_folder=base_output_folder,\n",
    "    generator_function=firework_async_generate,\n",
    "    base_url=ollama_base_url,\n",
    "    api_key=ollama_api_key\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runpod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qwen-2.5-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_configs = [  \n",
    "\n",
    "    {\n",
    "        'experiment_name': 'Qwen-2.5-3b',\n",
    "        'excel_path': r\"C:\\Users\\LEGION\\Documents\\GIT\\LLM_answer_GIBoard\\DO_NOT_PUBLISH\\ACG self asses - 202412\\New results\\E1_Bestprompt-2022_all_Final_E2_manualevaluatedcompleted_Final_E2_Final.xlsx\",\n",
    "        \n",
    "        # 'excel_path': r\"C:\\Users\\LEGION\\Documents\\GIT\\LLM_answer_GIBoard\\DO_NOT_PUBLISH\\ACG self asses - 202412\\New results\\E1_Bestprompt-2022_all_Final_E2_manualevaluatedcompleted_Final_E2_Final.xlsx\",\n",
    "        'prompt_column': 'TEXT4WEB',\n",
    "        'temperature': 0.6,\n",
    "        'model':  'Qwen/Qwen2.5-7B-Instruct',\n",
    "        \n",
    "        'max_tokens': 1024,\n",
    "        'system_prompt': None, # \"You are a helpful assistant.\"\n",
    "        'batch_size': 4,\n",
    "        # pydantic_model = ,\n",
    "        # \"model_kwargs\" = {},\n",
    "        # \"start_row\" = 0,\n",
    "        # \"end_row\"=None,\n",
    "        # image_column = ,\n",
    "    },        \n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nest_asyncio\n",
    "import asyncio\n",
    "from handlers.async_experiment_handler import run_multiple_experiments\n",
    "from generation.firework.async_generator import firework_async_generate\n",
    "\n",
    "\n",
    "base_output_folder = r\"C:\\Users\\LEGION\\Documents\\GIT\\LLM_answer_GIBoard\\DO_NOT_PUBLISH\\ACG self asses - 202412\\New results\"\n",
    "runpod_base_url=\"https://api.runpod.ai/v2/kusvo8y5bfq5ew/openai/v1\"\n",
    "runpod_api_key = os.getenv(\"RUNPOD_API_KEY\")\n",
    "\n",
    "\n",
    "results = await run_multiple_experiments(\n",
    "    experiment_configs=experiment_configs,\n",
    "    base_output_folder=base_output_folder,\n",
    "    generator_function=firework_async_generate,\n",
    "    base_url=runpod_base_url,\n",
    "    api_key=runpod_api_key\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run - E0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Firework (llama3.1, qwen, phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_configs = [  \n",
    "\n",
    "    {\n",
    "        'experiment_name': 'Llama-3.1-8b', #游릭\n",
    "        'excel_path': r\"C:\\Users\\LEGION\\Documents\\GIT\\LLM_answer_GIBoard\\DO_NOT_PUBLISH\\ACG self asses - 202412\\New results E0\\E0-60Q.xlsx\",\n",
    "        \n",
    "        # 'excel_path': r\"C:\\Users\\LEGION\\Documents\\GIT\\LLM_answer_GIBoard\\DO_NOT_PUBLISH\\ACG self asses - 202412\\New results\\E1_Bestprompt-2022_all_Final_E2_manualevaluatedcompleted_Final_E2_Final.xlsx\",\n",
    "        'prompt_column': 'TEXT4WEB',\n",
    "        'temperature': 0.6,\n",
    "        'model':  'accounts/fireworks/models/llama-v3p1-8b-instruct',\n",
    "        \n",
    "        'max_tokens': 1024,\n",
    "        'system_prompt': None,\n",
    "        'batch_size': 30,\n",
    "        # pydantic_model = ,\n",
    "        # \"model_kwargs\" = {},\n",
    "        # \"start_row\" = 0,\n",
    "        # \"end_row\"=None,\n",
    "        # image_column = ,\n",
    "    },        \n",
    "    {\n",
    "        'experiment_name': 'Llama-3.1-70b', #游릭\n",
    "        'excel_path': r\"C:\\Users\\LEGION\\Documents\\GIT\\LLM_answer_GIBoard\\DO_NOT_PUBLISH\\ACG self asses - 202412\\New results E0\\E0-60Q.xlsx\",\n",
    "        \n",
    "        # 'excel_path': r\"C:\\Users\\LEGION\\Documents\\GIT\\LLM_answer_GIBoard\\DO_NOT_PUBLISH\\ACG self asses - 202412\\New results\\E1_Bestprompt-2022_all_Final_E2_manualevaluatedcompleted_Final_E2_Final.xlsx\",\n",
    "        'prompt_column': 'TEXT4WEB',\n",
    "        'temperature': 0.6,\n",
    "        'model':  'accounts/fireworks/models/llama-v3p1-70b-instruct',\n",
    "        \n",
    "        'max_tokens': 1024,\n",
    "        'system_prompt': None,\n",
    "        'batch_size': 30,\n",
    "        # pydantic_model = ,\n",
    "        # \"model_kwargs\" = {},\n",
    "        # \"start_row\" = 0,\n",
    "        # \"end_row\"=None,\n",
    "        # image_column = ,\n",
    "    },  \n",
    "    {\n",
    "        'experiment_name': 'Phi-3.5-4b', #游릭\n",
    "        'excel_path': r\"C:\\Users\\LEGION\\Documents\\GIT\\LLM_answer_GIBoard\\DO_NOT_PUBLISH\\ACG self asses - 202412\\New results E0\\E0-60Q.xlsx\",\n",
    "        \n",
    "        # 'excel_path': r\"C:\\Users\\LEGION\\Documents\\GIT\\LLM_answer_GIBoard\\DO_NOT_PUBLISH\\ACG self asses - 202412\\New results\\E1_Bestprompt-2022_all_Final_E2_manualevaluatedcompleted_Final_E2_Final.xlsx\",\n",
    "        'prompt_column': 'TEXT4WEB',\n",
    "        'temperature': 0.6,\n",
    "        'model':  'accounts/fireworks/models/phi-3-vision-128k-instruct',\n",
    "        \n",
    "        'max_tokens': 1024,\n",
    "        'system_prompt': None,\n",
    "        'batch_size': 30,\n",
    "        # pydantic_model = ,\n",
    "        # \"model_kwargs\" = {},\n",
    "        # \"start_row\" = 0,\n",
    "        # \"end_row\"=None,\n",
    "        # image_column = ,\n",
    "    },      \n",
    "\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nest_asyncio\n",
    "import asyncio\n",
    "from Clean.handlers.async_experiment_handler import run_multiple_experiments\n",
    "from generation.firework.async_generator import firework_async_generate\n",
    "\n",
    "\n",
    "base_output_folder = r\"C:\\Users\\LEGION\\Documents\\GIT\\LLM_answer_GIBoard\\DO_NOT_PUBLISH\\ACG self asses - 202412\\New results E0\"\n",
    "firework_base_url=\"https://api.fireworks.ai/inference/v1\"\n",
    "firework_api_key = os.getenv(\"FIREWORKS_API_KEY\")\n",
    "\n",
    "\n",
    "results = await run_multiple_experiments(\n",
    "    experiment_configs=experiment_configs,\n",
    "    base_output_folder=base_output_folder,\n",
    "    generator_function=firework_async_generate,\n",
    "    base_url=firework_base_url,\n",
    "    api_key=firework_api_key\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI (gpt-4o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_configs = [  \n",
    "\n",
    "    {\n",
    "        'experiment_name': 'GPT-4o', #游릭\n",
    "        'excel_path': r\"C:\\Users\\LEGION\\Documents\\GIT\\LLM_answer_GIBoard\\DO_NOT_PUBLISH\\ACG self asses - 202412\\New results E0\\E0-60Q.xlsx\",\n",
    "        \n",
    "        \n",
    "        # 'excel_path': r\"C:\\Users\\LEGION\\Documents\\GIT\\LLM_answer_GIBoard\\DO_NOT_PUBLISH\\ACG self asses - 202412\\New results\\E1_Bestprompt-2022_all_Final_E2_manualevaluatedcompleted_Final_E2_Final.xlsx\",\n",
    "        'prompt_column': 'TEXT4WEB',\n",
    "        'temperature': 1,\n",
    "        'model':  'gpt-4o-2024-08-06',\n",
    "        \n",
    "        'max_tokens': 1024,\n",
    "        'system_prompt': None,\n",
    "        'batch_size': 30,\n",
    "        # pydantic_model = ,\n",
    "        # \"model_kwargs\" = {},\n",
    "        # \"start_row\" = 0,\n",
    "        # \"end_row\"=None,\n",
    "        # image_column = ,\n",
    "    },        \n",
    "    \n",
    "\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nest_asyncio\n",
    "import asyncio\n",
    "from handlers.async_experiment_handler import run_multiple_experiments\n",
    "from generation.firework.async_generator import firework_async_generate\n",
    "\n",
    "\n",
    "base_output_folder = r\"C:\\Users\\LEGION\\Documents\\GIT\\LLM_answer_GIBoard\\DO_NOT_PUBLISH\\ACG self asses - 202412\\New results E0\"\n",
    "openai_base_url=\"https://api.openai.com/v1/\"\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "results = await run_multiple_experiments(\n",
    "    experiment_configs=experiment_configs,\n",
    "    base_output_folder=base_output_folder,\n",
    "    generator_function=firework_async_generate,\n",
    "    base_url=openai_base_url,\n",
    "    api_key=openai_api_key\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run app code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code generated by ezExperiment Runner\n",
    "\n",
    "import os\n",
    "import nest_asyncio\n",
    "import asyncio\n",
    "import pandas as pd\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "from pathlib import Path\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from handlers.async_experiment_handler import run_multiple_experiments\n",
    "from generation.firework.async_generator import firework_async_generate\n",
    "from mytest.mytest import test_llm_functions\n",
    "\n",
    "# validate api\n",
    "api_key_var = \"FIREWORKS_API_KEY\"\n",
    "api_key = os.getenv(api_key_var)\n",
    "if api_key is None:\n",
    "    raise ValueError(\"Please check your api key. You should save it in .env file and load it here.\")\n",
    "##########################\n",
    "###    ezExperiments   ###\n",
    "##########################\n",
    "experiment_configs = [\n",
    "    {\n",
    "        'experiment_name': \"my_experiment_1\",\n",
    "        'excel_path': \"mytest\\\\test_content\\\\test_prompt.xlsx\",\n",
    "        'prompt_column': \"My_prompt\",\n",
    "        'temperature': 1.0,\n",
    "        'model': \"accounts/fireworks/models/llama-v3p2-1b-instruct\",\n",
    "        'max_tokens': 1024,\n",
    "        'system_prompt': None,\n",
    "        'batch_size': 30,\n",
    "        'start_row': 0,\n",
    "        'end_row': None,\n",
    "    },\n",
    "    {\n",
    "        'experiment_name': \"my_experiment_2\",\n",
    "        'excel_path': \"mytest\\\\test_content\\\\test_prompt.xlsx\",\n",
    "        'prompt_column': \"My_prompt\",\n",
    "        'temperature': 1.0,\n",
    "        'model': \"accounts/fireworks/models/llama-v3p2-3b-instruct\",\n",
    "        'max_tokens': 1024,\n",
    "        'system_prompt': None,\n",
    "        'batch_size': 30,\n",
    "        'start_row': 0,\n",
    "        'end_row': None,\n",
    "        'pydantic_model': \"Radiologist\",\n",
    "    },\n",
    "]\n",
    "\n",
    "base_output_folder = \"C:\\\\path\\\\to\\\\output\"\n",
    "base_url = \"https://api.fireworks.ai/inference/v1\"\n",
    "api_key = api_key\n",
    "\n",
    "# Pydantic models defined by user:\n",
    "class Radiologist(BaseModel):\n",
    "    name: str = Field(description=\"name of radiologist\")\n",
    "\n",
    "pydantic_models = {\n",
    "    'my_experiment_2': Radiologist,\n",
    "}\n",
    "\n",
    "\n",
    "async def main():\n",
    "    results = await run_multiple_experiments(\n",
    "        experiment_configs=experiment_configs,\n",
    "        base_output_folder=base_output_folder,\n",
    "        generator_function=firework_async_generate,\n",
    "        base_url=base_url,\n",
    "        api_key=api_key,\n",
    "        pydantic_models=pydantic_models\n",
    "    )\n",
    "    return results\n",
    "\n",
    "loop = asyncio.get_event_loop()\n",
    "final_results = loop.run_until_complete(main())\n",
    "print(\"All experiments complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
